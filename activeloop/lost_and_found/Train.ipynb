{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6.9 64-bit ('venv': venv)",
      "language": "python",
      "name": "python36964bitvenvvenv2f96fd8b646d44e3b9e0885369a63a85"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "equivalent-classic"
      },
      "source": [
        "## Install required libraries"
      ],
      "id": "equivalent-classic"
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "sexual-chance"
      },
      "source": [
        "!pip install hub\n",
        "!pip install matplotlib\n",
        "!pip install torch\n",
        "!pip install segmentation_models_pytorch"
      ],
      "id": "sexual-chance",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swiss-jacksonville"
      },
      "source": [
        "## Imports"
      ],
      "id": "swiss-jacksonville"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoVMl2y4EAUx"
      },
      "source": [
        "!hub login"
      ],
      "id": "XoVMl2y4EAUx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "particular-implementation"
      },
      "source": [
        "import psutil\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import ConcatDataset\n",
        "import torch\n",
        "from torch.utils.data import random_split\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "import hub\n",
        "from hub.compute.transforms_generic.ds_transforms import shift_scale_rotate, gaussian_noise\n",
        "from hub.api.sharded_datasetview import ShardedDatasetView"
      ],
      "id": "particular-implementation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "understanding-circus"
      },
      "source": [
        "## Load the dataset"
      ],
      "id": "understanding-circus"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "julian-territory"
      },
      "source": [
        "ds = hub.load(\"activeloop/lost_and_found_semantic_segmentation_train\")\n",
        "ds_test = hub.load(\"activeloop/lost_and_found_semantic_segmentation_test\")"
      ],
      "id": "julian-territory",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "going-avatar"
      },
      "source": [
        "## Augment images and add to the original Dataset"
      ],
      "id": "going-avatar"
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "relative-murray"
      },
      "source": [
        "ds_augmented = shift_scale_rotate(ds, keys=['image_left', 'segmentation_label'], rotate_limit=0, shift_limit=0.1)\n",
        "ds_augmented = gaussian_noise(ds_augmented, keys=['image_left'])\n",
        "ds_augmented = ds_augmented.store(\"/tmp/lost_and_found_aug\")\n",
        "ds_sharded = ShardedDatasetView([ds, ds_augmented])\n",
        "\n",
        "@hub.transform(schema=ds_sharded.schema, scheduler=\"threaded\", workers=psutil.cpu_count() - 1)\n",
        "def transform_identity(sample):\n",
        "    return sample\n",
        "\n",
        "ds = transform_identity(ds_sharded).store('/tmp/lost_and_found_all')"
      ],
      "id": "relative-murray",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgPbn9nkT2yu"
      },
      "source": [
        "model = smp.Unet('resnet50',\n",
        "            classes=39,\n",
        "            in_channels=3,\n",
        "        )\n",
        "iou = smp.utils.metrics.IoU(eps=1.0, activation=None, threshold=0.5)\n",
        "loss = smp.utils.losses.DiceLoss()\n",
        "optimizer = torch.optim.Adam([ \n",
        "    dict(params=model.parameters(), lr=0.0001),\n",
        "])\n",
        "train_epoch = smp.utils.train.TrainEpoch(\n",
        "  model, \n",
        "  loss=loss, \n",
        "  metrics=[iou], \n",
        "  optimizer=optimizer,\n",
        "  device='cuda',\n",
        "  verbose=True,\n",
        ")\n",
        "\n",
        "valid_epoch = smp.utils.train.ValidEpoch(\n",
        "    model, \n",
        "    loss=loss, \n",
        "    metrics=[iou],\n",
        "    device='cuda',\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "\n",
        "def train(train_loader: torch.utils.data.DataLoader, val_loader: torch.utils.data.DataLoader):\n",
        "  max_score = 0\n",
        "\n",
        "  for i in range(0, 10):      \n",
        "      print('\\nEpoch: {}'.format(i))\n",
        "      train_logs = train_epoch.run(train_loader)\n",
        "      valid_logs = valid_epoch.run(val_loader)\n",
        "      \n",
        "      # do something (save model, change lr, etc.)\n",
        "      if max_score < valid_logs['iou_score']:\n",
        "          max_score = valid_logs['iou_score']\n",
        "          torch.save(model, './best_model.pth')\n",
        "          print('Model saved!')\n",
        "          \n",
        "      if i == 25:\n",
        "          optimizer.param_groups[0]['lr'] = 1e-5\n",
        "          print('Decrease decoder learning rate to 1e-5!')"
      ],
      "id": "BgPbn9nkT2yu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z3ofyVnUF6J"
      },
      "source": [
        "def transform(sample):\n",
        "  img = sample['image_left'].permute(2, 0, 1).float()\n",
        "  mask = sample['segmentation_label'].permute(2, 0, 1).float()\n",
        "  return img, mask\n",
        "\n",
        "torch_ds = ds.to_pytorch(key_list=['image_left', 'segmentation_label'], output_type=tuple, transform=transform)\n",
        "torch_ds_test = ds_test.to_pytorch(key_list=['image_left', 'segmentation_label'], output_type=tuple, transform=transform)\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "        torch_ds,\n",
        "        batch_size=1,\n",
        "        shuffle=True,\n",
        "        num_workers=4\n",
        "    )\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "        torch_ds_test,\n",
        "        batch_size=1,\n",
        "        shuffle=False,\n",
        "        num_workers=4\n",
        "    )\n",
        "train(train_dataloader, val_dataloader)"
      ],
      "id": "7Z3ofyVnUF6J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEb1HkX7UIgX"
      },
      "source": [
        ""
      ],
      "id": "LEb1HkX7UIgX",
      "execution_count": null,
      "outputs": []
    }
  ]
}