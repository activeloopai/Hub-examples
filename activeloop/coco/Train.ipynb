{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6.9 64-bit ('venv': venv)",
      "language": "python",
      "name": "python36964bitvenvvenv2f96fd8b646d44e3b9e0885369a63a85"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04noYLPpZUmt"
      },
      "source": [
        "## Install required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "AlPByzSRZUm9"
      },
      "source": [
        "!pip install hub\n",
        "!pip install matplotlib\n",
        "!pip install torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhctLDk5ZUm-"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlDh5MuQZUm_"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import ConcatDataset\n",
        "import torch\n",
        "from torch.utils.data import random_split\n",
        "import hub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJu4NzWEZpEp"
      },
      "source": [
        "!hub login"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4Kb0YgMZUnA"
      },
      "source": [
        "## Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2zegJsuZUnA"
      },
      "source": [
        "ds = hub.load(\"activeloop/activeloop/coco_train\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUZ5g6zhZUnB"
      },
      "source": [
        "## Define a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2B2QSKZZUnB"
      },
      "source": [
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "import torchvision\n",
        "\n",
        "\n",
        "def get_model_instance_segmentation(num_classes):\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False)\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    return model\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "num_classes = 92\n",
        "num_epochs = 10\n",
        "model = get_model_instance_segmentation(num_classes)\n",
        "model.to(device)\n",
        "\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "\n",
        "def train(data_loader):\n",
        "    len_dataloader = len(data_loader)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        i = 0    \n",
        "        print(\"Start training\")\n",
        "        for imgs, annotations in data_loader:\n",
        "            i += 1\n",
        "            imgs = list(img.to(device) for img in imgs if img is not None)\n",
        "            annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations if t is not None]\n",
        "            loss_dict = model(imgs, annotations)\n",
        "            losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            losses.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            print(f'Iteration: {i}/{len_dataloader}, Loss: {losses}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm-A4z7Xblvn"
      },
      "source": [
        "## Convert to PyTorch dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHgzAtXVZUnD"
      },
      "source": [
        "def get_transform():\n",
        "    custom_transforms = []\n",
        "    custom_transforms.append(torchvision.transforms.ToTensor())\n",
        "    return torchvision.transforms.Compose(custom_transforms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahHM23clZUnD"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "\n",
        "class CocoDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, ds, transforms=None):\n",
        "        self.transforms = transforms\n",
        "        self.ds = ds\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        img = self.ds[index]['image'].compute()\n",
        "        objs = self.ds[index]['objects'].compute()\n",
        "        num_objs = len(objs['bbox'])\n",
        "        boxes = []\n",
        "        for i in range(num_objs):\n",
        "            xmin = objs['bbox'][i][0]\n",
        "            ymin = objs['bbox'][i][1]\n",
        "            xmax = xmin + objs['bbox'][i][2]\n",
        "            ymax = ymin + objs['bbox'][i][3]\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        if boxes.shape == torch.Size([0]):\n",
        "          return None, None\n",
        "        labels = torch.tensor(objs['label'], dtype=torch.int64)\n",
        "        areas = []\n",
        "        for i in range(num_objs):\n",
        "            areas.append(objs['area'][i])\n",
        "        areas = torch.as_tensor(areas, dtype=torch.float32)\n",
        "        iscrowd = torch.tensor(objs['is_crowd'], dtype=torch.int64)\n",
        "\n",
        "        my_annotation = {}\n",
        "        my_annotation[\"boxes\"] = boxes\n",
        "        my_annotation[\"labels\"] = labels\n",
        "        my_annotation[\"area\"] = areas\n",
        "        my_annotation[\"iscrowd\"] = iscrowd\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        return img, my_annotation\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1PZwFLEbvCg"
      },
      "source": [
        "## Train\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwXbsv6NZUnE"
      },
      "source": [
        "torch_ds_train = CocoDataset(ds, transforms=get_transform())\n",
        "\n",
        "def collate_fn(batch):\n",
        "    len_batch = len(batch) \n",
        "    batch = list(filter (lambda x:x is not None, batch))\n",
        "    if len_batch > len(batch):\n",
        "        diff = len_batch - len(batch)\n",
        "        for i in range(diff):\n",
        "            batch = batch + batch[:diff]\n",
        "    return tuple(zip(*batch))\n",
        "    \n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "        torch_ds_train,\n",
        "        batch_size=4,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_fn\n",
        "    )\n",
        "train(train_dataloader)\n",
        "torch.save(model, \"/tmp/model_coco.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6zTIrfVbrc5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkpCQdk6ZUnG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}